<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <title>Manual</title>
  </head>
  <body>
    <h1>Manual to 3D Classification Survey</h1>
    <p><br>
    </p>
    <h2>Abstract</h2>
    <p><i>We compiled set of publicly available neural networks for
        classification of 3D models. The code works with ModelNet40 and
        ShapeNetCore datasets which are also available online. This is a manual
        explaining how to convert datasets, train and test these networks. <br>
      </i></p>
    <h2>Requirements</h2>
    <p>To run the code you will need a computer with Linux operating system and
      NVIDIA GPU.</p>
    <p>You will need to install:</p>
    <ul>
      <li>NVIDIA drivers (<a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#package-manager-installation"
          target="_blank">Installation guide here</a>)</li>
      <li>Docker version 1.12 or higher (<a href="https://docs.docker.com/install/"
          target="_blank">Installation guide here</a><span style="color: black;">)</span></li>
      <li><span style=" color: black;">NVIDIA Container Runtime for Docker (<a href="https://github.com/NVIDIA/nvidia-docker"
            target="_blank">Installation guide here</a>)</span></li>
    </ul>
    <p><span style="  color: black;">And that is all! Each neural network is an
        independent Docker image and all its dependencies are installed when
        building the image. All code is written in python.<br>
      </span></p>
    <h2><span style="  color: black;">Datasets Setup</span></h2>
    <p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span
        style="color: black;">The code is made to work with ModelNet40 and
        ShapeNetCore datasets. The easiest way to run it with custom dataset is
        to restructure your data so it copies the structure of one of these
        datasets. <span style="font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"><br></span></span></p>
    <ul>
      <li>
        <h3 dir="ltr" style=" line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span
            style="color: black;"><span style="font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">ModelNet40</span></span><span
            style="color: black;"><span style="font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"></span><br>
          </span></h3>
        <ul>
          <li><span style="color: black;"><span style="font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Get the dataset <a
href="http://modelnet.cs.princeton.edu/" target="_blank">here</a>. For experiments we used manually aligned version which can be downloaded <a
href="https://github.com/lmb-freiburg/orion" target="_blank">here</a>.</span></span></li>
        </ul>
      </li>
      <ul>
        <li><span style=" color: black;"><span style=" font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Unpack the downloaded archive and you are ready to go!<br></span></span></li>
      </ul>
    </ul>
    <span style=" color: black;"><span style=" font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"></span></span>
    <ul>
      <li>ShapeNetCore</li>
      <ul>
        <li><span style="color: black;"><span style="font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Get the dataset <a
href="https://www.shapenet.org/download/shapenetcore" target="_blank">here</a>. You need to register and wait for confirmation email.</span></span></li>
        <li><span style=" color: black;"><span style=" font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Unpack the downloaded archive.</span></span></li>
        <li><span style="  color: black;"><span style="  font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Download official dataset split <a
href="http://shapenet.cs.stanford.edu/shapenet/obj-zip/SHREC16/all.csv" target="_blank">here</a> and copy it to the root directory of the dataset.</span></span></li>
      </ul>
    </ul>
    <h2>General Setup</h2>
    <p>You can download all the code from Github <a href="https://github.com/Alobal123/diplomka"
        target="_blank">here</a>.</p>
    <p>Each network is implemented as a separate Docker image. To learn more
      about Docker, images and containers visit <a href="https://docs.docker.com/get-started/"
        target="_blank">this page</a>.</p>
    <p>Each neural network is contained in one directory in <i>/dockers</i>.
      None of the networks accepts mesh files as their input directly, so some
      data conversion is required. All data conversion is implemented in docker
      with same structure as neural networks themselves. Code for data
      conversion is located in <i>/dockers/data_conversion</i>.</p>
    <p>Each directory contains two important files - <b>config.ini</b> and <b>run.sh</b>,
      which you will need to open and edit. Another important file is <b>Dockerfile</b>
      which contains the definition of the docker image. Remaining files contain
      the code which differ from the original network implementation. Original
      network code is downloaded automatically when building the image and you
      can find the download link below.</p>
    <p><b>run.sh </b>is a runnable script which builds the docker image, runs
      the docker container and executes the neural network or data conversion.
      You will need to setup a couple of variables here:</p>
    <ul>
      <li><code><i>name </i></code>- will be used as a name of the docker image
        and docker container. You can leave this at default value unless it is
        in conflict with some already existing image or you want to run more
        instances of this image at once. With data conversion scripts the name
        is the name of the converted dataset and directory of the same name will
        be created. The name of the image can be changed by changing variable <i>image_name
          </i>in this case.</li>
      <li><code><i>dataset_path</i></code> -&nbsp; contains path to the root
        directory of the dataset on your filesystem.</li>
      <li><code><i>out_path</i> </code>- contains path to the directory where
        training logs and network weights will be saved. This directory will be
        created automatically.</li>
      <li><code><i>GPU</i></code> - index of GPU which will be visible to docker
        container. Have to be a single integer. We currently do not support
        multiple GPUs.</li>
      <li><code><i>docker_hidden</i> </code>- Must be one of <code><i>t</i></code>
        or <code><i>d</i></code>. With<code> </code><i><code>t</code> </i>the
        container will be run in interactive mode, meaning it will run in your
        console. With <code><i>d</i></code> it will in detached mode i.e. in
        the background. For more information check docker documentation <a href="https://docs.docker.com/engine/reference/run/"
          target="_blank">here</a>.</li>
    </ul>
    <p><b>config.ini</b> contains most of the relevant parameters of the network
      or data conversion. The file is split to sections where each section is
      started by [SECTION] statement. Then on each line a parameter in format <i>key
        = value</i>. You can find explanation of network parameters in later
      sections. </p>
    <p></p>
    <ul>
    </ul>
    <h2> Data conversion</h2>
    <p>To convert your dataset you need to set the parameters described above
      and then simply run script <i>run.sh </i>in your console. This will
      convert the dataset to various formats directly readable by the neural
      networks.</p>
    <p>Parameters for data conversion in <i>config.ini</i> file: </p>
    <ul>
      <li><i><code>data</code> </i>- path to the dataset inside the container.
        Does not have to be changed.</li>
      <li><i><code>output </code></i>- path to the directory inside the
        container where converted dataset will be saved. Does not have to be
        changed.</li>
      <li><code>log_file - </code>path and name of the file where progress of
        the data conversion will be written.</li>
      <li><code>num_threads - </code>maximum number of threads to use.</li>
      <li><code>dataset_type</code> -&nbsp; which dataset is converting. Must be
        one of <code>modelnet</code> or <code>shapenet </code>currently.</li>
    </ul>
    <p><b>For more detail about individual data conversion scripts, continue <a
          href="conversions.html" target="_top">here</a>.</b></p>
    <h2>Neural Networks</h2>
    <p>Each of the neural networks is implemented in python but in different
      framework. That is why we used the docker infrastructure. We try to
      present some unified framework to easily test and train the networks
      without changing the code. This section will briefly introduce used
      networks and some of their most important parameters. </p>
    <p>Parameters common to all neural networks: </p>
    <ul>
      <li><code><i>name</i></code> - will be used as the name of the experiment
        used in log files.</li>
      <li><i><code>data</code> </i>- path to the dataset inside the container.
        Does not have to be changed.</li>
      <li><i><code>log_dir</code> </i>- path to the directory inside the
        container where logs and weights will be saved. Does not have to be
        changed.</li>
      <li><i><code>num_classes</code></i> - number of classes in the dataset. </li>
      <li><i><code>batch_size</code> - </i>size of the batch for training and
        testing neural networks.</li>
      <li><i><code>weights</code> - </i>if you want to test or finetune already
        trained network, this should be the number of this model. If you want to
        train from scratch, this should be -1. </li>
      <li><i><code>snapshot_prefix</code> - </i>name of the file where weights
        will be saved. Number of training epoch when these weights are saved
        will be added to this.</li>
    </ul>
    <ul>
      <li><i><code>max_epoch</code> - </i>number of epochs to train for. One
        epoch means one pass through the training part of the dataset. </li>
      <li><i><code>save_period</code> - </i>the trained network will be saved
        every epoch divisible by save_period. </li>
      <li><code>train_log_frq</code> - frequency of logging during training. It
        is roughly number of examples seen by network.</li>
    </ul>
    <ul>
      <li> <i><code>test</code> - </i>if you want to only test already trained
        network, set this to True. <i><code>weights</code> </i>parameter has
        to have a valid value bigger than -1. Should be <code>False</code> for
        training. </li>
    </ul>
    <p><b>For more details about individual networks, continue <a href="networks.html"
          target="_top">here</a>.</b></p>
    <h2>Logging and Evaluation</h2>
    <p>Our framework offers some basic logging options. It saves several<i> .csv
      </i>to the logging directory. The logger keeps track of time of the
      training, training epochs and some other value. By default four values are
      tracked: training loss, training accuracy, test loss and test accuracy.
      Evaluation on the test set is performed after each epoch of training. Also
      some basic graphs using matplotlib library are created and saved during
      training. When testing your already trained network (using <code>test =
        True</code>) text file is saved where network category prediction is
      saved along with a simple html confusion matrix. </p>
    <p><br>
    </p>
    <p> </p>
  </body>
</html>
