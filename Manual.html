<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <title>Manual</title>
  </head>
  <body>
    <h1>Manual to 3D Classification Survey</h1>
    <p><br>
    </p>
    <h2>Abstract</h2>
    <p><i>I compiled set of publicly available neural networks for
        classification of 3D models. I made the code work with ModelNet40 and
        ShapeNetCore datasets which are also available online. This is a manual
        explaining how to run the code and train or test all networks.</i></p>
    <h2>Requirements</h2>
    <p>To run the code you will need a computer with Linux operating system and
      NVIDIA GPU.</p>
    <p>You will need to install:</p>
    <ul>
      <li>NVIDIA drivers (<a href="https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#package-manager-installation">Installation
          guide here</a>)</li>
      <li>Docker version 1.12 or higher (<a href="https://docs.docker.com/install/">Installation
          guide here</a><span style="color: black;">)</span></li>
      <li><span style=" color: black;">NVIDIA Container Runtime for Docker (<a href="https://github.com/NVIDIA/nvidia-docker">Installation
            guide here</a>)</span></li>
    </ul>
    <p><span style="  color: black;">And that is all! Each neural network is an
        independent Docker image and all its dependencies are installed when
        building the image.</span></p>
    <h2><span style="  color: black;">Datasets Setup</span></h2>
    <p dir="ltr" style="line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span
        style="color: black;">The code is made to work with ModelNet40 and
        ShapeNetCore datasets. The easiest way to run it with custom dataset is
        to restructure your data to copy the structure of one of these datasets.
        <span style="font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"><br></span></span></p>
    <ul>
      <li>
        <h3 dir="ltr" style=" line-height:1.38;margin-top:0pt;margin-bottom:0pt;"><span
            style="color: black;"><span style="font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">ModelNet40</span></span><span
            style="color: black;"><span style="font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"></span><br>
          </span></h3>
        <ul>
          <li><span style="color: black;"><span style="font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Get the dataset <a
href="http://modelnet.cs.princeton.edu/">here</a>. For experiments we used manually aligned version which can be downloaded <a
href="https://github.com/lmb-freiburg/orion">here</a>.</span></span></li>
        </ul>
      </li>
      <ul>
        <li><span style=" color: black;"><span style=" font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Unpack the downloaded archive and you are ready to go!<br></span></span></li>
      </ul>
    </ul>
    <span style=" color: black;"><span style=" font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;"></span></span>
    <ul>
      <li>ShapeNetCore</li>
      <ul>
        <li><span style="color: black;"><span style="font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Get the dataset <a
href="https://www.shapenet.org/download/shapenetcore">here</a>. You need to register and wait for confirmation email.</span></span></li>
        <li><span style=" color: black;"><span style=" font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Unpack the downloaded archive.</span></span></li>
        <li><span style="  color: black;"><span style="  font-size: 11pt; color: black; background-color: transparent; font-weight: 400; font-style: normal; font-variant: normal; text-decoration: none; vertical-align: baseline; white-space: pre-wrap;">Download official dataset split <a
href="http://shapenet.cs.stanford.edu/shapenet/obj-zip/SHREC16/all.csv">here</a> and copy it to the root directory of the dataset.</span></span></li>
      </ul>
    </ul>
    <h2>General Setup</h2>
    <p>You can download all the code <a href="https://github.com/Alobal123/diplomka">here</a>.</p>
    <p>Each network is implemented as a separate Docker image. To learn more
      about Docker, images and containers visit <a href="https://docs.docker.com/get-started/">this
        page</a>.</p>
    <p>Each neural network is contained in one directory in <i>/dockers</i> in
      my github repository. None of the networks accepts mesh files as their
      input directly, so some data conversion is required. All data conversion
      is implemented in docker with same structure as neural networks
      themselves. Code for data conversion is in <i>/dockers/data_conversion</i>.</p>
    <p>Each directory contains two files <b>config.ini</b> and <b>run.sh</b>
      which you will need to open and edit. Another important file is <b>Dockerfile</b>
      which is contains the definition of the docker image and is used to build
      it. Other files contain the code which differ from the original network
      implementation. Original network code is downloaded automatically when
      building the image and you can find the download link inside the
      Dockerfile.</p>
    <p><b>run.sh </b>is a runnable script which builds the docker image, runs
      the docker container and executes the neural network or data conversion.
      You will need to setup a couple of variables here:</p>
    <ul>
      <li><i>name </i>- will be used as a name of the docker image and docker
        container. You can leave this at default value unless it is in conflict
        with some already consisting image or you want to run more instances of
        this image at once. With data conversion scripts the name is the name of
        the converted dataset and directory of the same name will be created.
        The name of the image can be changed by changing variable <i>image_name</i>.</li>
      <li><i>dataset_path</i> -&nbsp; should contain path to the root directory
        to the dataset on your filesystem.</li>
      <li><i>out_path</i> - should contain path to the directory where training
        logs and network weights will be saved. The directory will be created if
        it does not exist.</li>
      <li><i>GPU</i> - index of GPU which will be visible to docker container.
        Have to be a single integer. We currently do not support multiple GPUs.</li>
      <li><i>docker_hidden</i> - Must be one of <i>t</i> or <i>d</i>. With <i>t
        </i>the container will be run in interactive mode, meaning it will run
        in your console. With <i>d</i> it will in detached mode i.e. in the
        background. For more information check docker documentation <a href="https://docs.docker.com/engine/reference/run/">here</a>.</li>
    </ul>
    <p><b>config.ini</b> contains most of the relevant parameters of the network
      or data conversion. The file is split to sections where each section is
      started by [SECTION] statement. Then on each line a parameter in format <i>key
        = value</i>. You can find explanation of network parameters in later
      sections. </p>
    <ul>
      <li><i>name</i> - will be used as the name of the experiment used in log
        files.</li>
      <li><i>data </i>- path to the dataset inside the container. Does not have
        to be changed.</li>
      <li><i>log_dir </i>- path to the directory inside the container where
        logs and weights will be saved. Does not have to be changed.</li>
      <li><i>num_classes</i> - number of classes in the dataset. </li>
      <li><i>batch_size - </i>size of the batch for training and testing neural
        networks.</li>
      <li><i>weights - </i>if you want to test or finetune already trained
        network, this should be the number of this model. If you want to train
        from scratch, this should be -1. </li>
      <li><i>snapshot_prefix - </i>name of the file where weights will be
        saved. Number of training epoch when these weights are saved will be
        added to this.</li>
    </ul>
    <ul>
      <li><i>max_epoch - </i>number of epochs to train for. One epoch means one
        pass through the training part of the dataset. </li>
      <li><i>save_period - </i>the trained network will be saved every epoch
        divisible by save_period.&nbsp;</li>
    </ul>
    <ul>
      <li><i>test - </i>if you want to only test already trained network, set
        this to True. <i>weights </i>parameter has to have a valid value
        bigger than -1. Should be False for training.</li>
    </ul>
    <ul>
    </ul>
    <p><br>
    </p>
    <p><br>
    </p>
    <p><br>
    </p>
    <p><br>
    </p>
    <p><br>
    </p>
    <p><br>
    </p>
    <p><br>
    </p>
    <p><br>
    </p>
    <p> </p>
    <p><span style="  color: black;"><br>
      </span></p>
    <p><br>
      <span style="  color: black;"></span></p>
    <p><br>
    </p>
  </body>
</html>
