[GENERAL]
name = SEQ2SEQ
data = /data
log_dir = ./logs
log_file = ./logs/log.txt
num_classes = 40
batch_size = 16
weights = -1
snapshot_prefix = model.ckpt-

[TRAINING]
max_epoch = 200
save_period = 20
learning_rate = 0.0002
train_log_frq = 1000
;droupout rate
keep_prob = 0.5

[TESTING]
test = False

[NET_SPECIFIC]
num_views = 12
use_lstm = False
decoder_embedding_size = 256
;number of hidden neurons
n_hidden = 128
;size of input feature
n_input_fc = 4096
use_attention = True
use_embedding = True
;Number of attention heads that read from attention_states
num_heads = 1

train_feature_file = /data/train_features.npy
train_label_file = /data/train_labels.npy
test_feature_file = /data/test_features.npy
test_label_file = /data/test_labels.npy

enrich_shapenet = False
enrich_data = False
